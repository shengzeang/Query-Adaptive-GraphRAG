[
  {
    "Question": "Which of the following statements about instruction encoding are true? (Select all that apply)",
    "Choices": {
      "A": "ARM and MIPS instructions are of fixed length.",
      "B": "80x86 instructions vary from 1 to 18 bytes in length.",
      "C": "Fixed-length instructions always result in smaller program size.",
      "D": "The number of registers affects instruction size in encoding."
    },
    "Level-1 Topic": "Computer architecture",
    "Level-2 Topic": "Instruction set architecture",
    "Rationale": "ARM and MIPS use fixed-length instructions for easier decoding, while 80x86 uses variable length, influencing program size and encoding complexity based on register and addressing mode counts.",
    "Answer": "ABD"
  },
  {
    "Question": "Which of the following statements about protection and instruction set architecture are true? (Select all that apply)",
    "Choices": {
      "A": "Virtual memory requires changes to existing instruction set architectures.",
      "B": "The IBM 370 instruction set was unchanged from the IBM 360.",
      "C": "Adjustments are being made today for virtual machines.",
      "D": "Protection is solely the responsibility of the operating system."
    },
    "Level-1 Topic": "Computer architecture",
    "Level-2 Topic": "Instruction set architecture",
    "Rationale": "Protection involves collaboration between architecture and operating systems. Virtual memory necessitates changes to ISAs, as seen with IBM 370's adaptations, and modern adjustments for virtual machines continue this trend.",
    "Answer": "AC"
  },
  {
    "Question": "Which of the following statements about exploiting instruction-level parallelism (ILP) are true? (Select all that apply)",
    "Choices": {
      "A": "Hardware can dynamically discover and exploit parallelism.",
      "B": "Software technology can find parallelism only at runtime.",
      "C": "Both hardware and software approaches can be used to exploit ILP.",
      "D": "Statically finding parallelism occurs at compile time."
    },
    "Level-1 Topic": "Computer architecture",
    "Level-2 Topic": "Pipelining and parallelism",
    "Rationale": "ILP can be exploited through hardware for dynamic parallelism and software for static parallelism. Both approaches complement each other in optimizing performance during execution and compilation.",
    "Answer": "ACD"
  },
  {
    "Question": "Which of the following are types of dependences in pipelining and parallelism? (Select all that apply)",
    "Choices": {
      "A": "Data dependences",
      "B": "Name dependences",
      "C": "Control dependences",
      "D": "Instruction dependences"
    },
    "Level-1 Topic": "Computer architecture",
    "Level-2 Topic": "Pipelining and parallelism",
    "Rationale": "The three types of dependences are data dependences, name dependences, and control dependences. Understanding these is crucial for optimizing instruction execution in pipelined architectures.",
    "Answer": "ABC"
  },
  {
    "Question": "Which of the following are categories of cache misses according to the three Cs model? (Select all that apply)",
    "Choices": {
      "A": "Compulsory misses",
      "B": "Capacity misses",
      "C": "Conflict misses",
      "D": "Coherence misses"
    },
    "Level-1 Topic": "Computer architecture",
    "Level-2 Topic": "Memory hierarchy",
    "Rationale": "The three Cs model categorizes cache misses into compulsory, capacity, and conflict misses, helping identify causes of high miss rates and guiding better cache design strategies.",
    "Answer": "ABC"
  },
  {
    "Question": "Which of the following are metrics used for cache optimizations? (Select all that apply)",
    "Choices": {
      "A": "Hit time",
      "B": "Miss rate",
      "C": "Cache size",
      "D": "Miss penalty"
    },
    "Level-1 Topic": "Computer architecture",
    "Level-2 Topic": "Memory hierarchy",
    "Rationale": "Cache optimizations focus on hit time, miss rate, and miss penalty to enhance performance. Understanding these metrics is crucial for developing effective cache strategies in memory hierarchies.",
    "Answer": "ABD"
  },
  {
    "Question": "Which of the following are classes of cache coherence protocols used in multiprocessor systems?",
    "Choices": {
      "A": "Directory-based",
      "B": "Snooping",
      "C": "Memory-mapped",
      "D": "Centralized"
    },
    "Level-1 Topic": "Computer architecture",
    "Level-2 Topic": "Thread-Level Parallelism",
    "Rationale": "Directory-based and snooping protocols are key techniques for maintaining cache coherence among processors, each employing different methods to track data sharing and access states effectively.",
    "Answer": "AB"
  },
  {
    "Question": "Which of the following are components of execution time in a multi-processor system?",
    "Choices": {
      "A": "Idle",
      "B": "User",
      "C": "Synchronization",
      "D": "I/O"
    },
    "Level-1 Topic": "Computer architecture",
    "Level-2 Topic": "Thread-Level Parallelism",
    "Rationale": "Execution time consists of Idle, User, and Synchronization components, representing different states of processor activity. I/O is not included in this breakdown.",
    "Answer": "ABC"
  },
  {
    "Question": "Which of the following roles does the uninterruptible power supply (UPS) play in a warehouse-scale computer (WSC)? (Select all that apply)",
    "Choices": {
      "A": "Power conditioning",
      "B": "Providing backup power only",
      "C": "Holding the load during generator startup",
      "D": "Switching back to electrical utility load"
    },
    "Level-1 Topic": "Computer architecture",
    "Level-2 Topic": "Warehouse-Scale Computers to Exploit Request-Level and Data-Level Parallelism",
    "Rationale": "The UPS is essential for maintaining voltage, supporting power during generator transitions, and ensuring smooth operation, while its efficiency leads to some energy loss and significant cost.",
    "Answer": "ACD"
  },
  {
    "Question": "Which of the following advantages were reported for warehouse-scale computers (WSCs) compared to a datacenter with only 1000 servers? (Select all that apply)",
    "Choices": {
      "A": "5.7 times reduction in storage costs",
      "B": "7.1 times reduction in administrative costs",
      "C": "3 times increase in hardware costs",
      "D": "7.3 times reduction in networking costs"
    },
    "Level-1 Topic": "Computer architecture",
    "Level-2 Topic": "Warehouse-Scale Computers to Exploit Request-Level and Data-Level Parallelism",
    "Rationale": "WSCs achieved significant reductions in storage, administrative, and networking costs due to economies of scale, while option C incorrectly implies an increase in hardware costs.",
    "Answer": "ABD"
  },
  {
    "Question": "Given the multi-process program below, which of the following are infeasible output(s) of the program?\nPS: fflush(stdout) is a function to flush the standard output immediately, so that before the next printf() is invoked, the output buffer is empty.\nint main()\n{\n   printf(\"A\"); fflush(stdout);\n   if (fork() == 0){\n     printf(\"B\"); fflush(stdout);\n     if (fork() == 0){\n       printf(\"C\"); fflush(stdout);\n       exit(1);\n     }\n     printf(\"D\"); fflush(stdout);\n     exit(2);\n   }\n   printf(\"C\"); fflush(stdout);\n   exit(0);\n}",
    "Choices": {
      "A": "ABCCD",
      "B": "BADCC",
      "C": "ACCBD",
      "D": "ADBCC"
    },
    "Level-1 Topic": "Operating systems",
    "Level-2 Topic": "Process management and concurrency",
    "Rationale": "Outputs B,C, D are infeasible due to incorrect process termination or output sequence based on fork behavior.",
    "Answer": "BCD"
  },
  {
    "Question": "Given the following program, which modification(s) can improve the locality of the program?\n#define N 20\nint summarize (int a[N][N][N])\n{\n int i, j, k;\n int sum = 0;\n for (i = 0; i < N; i++)\n for (j = 0; j < N; j++)\n for (k = 0; k < N; k++)\n sum += a[k][i][j];\n}",
    "Choices": {
      "A": "sum += a[ k ][ j ][ i ];",
      "B": "sum += a[ j ][ i ][ k ];",
      "C": "sum += a[ j ][ k ][ i ];",
      "D": "sum += a[ i ][ k ][ j ];"
    },
    "Level-1 Topic": "Computer architecture",
    "Level-2 Topic": "Cache optimization and memory locality",
    "Rationale": "B, C, and D improve locality by matching memory access patterns with memory layout, enhancing cache efficiency.",
    "Answer": "BCD"
  },
  {
    "Question": "(multi-answer) Which of the following statements are true about cosine similarity of two data samples in vector representation? Select all that apply.",
    "Choices": {
      "A": "Cosine similarity is a measure of the angle between two vectors.",
      "B": "Cosine similarity is always between 0 and 1.",
      "C": "Cosine similarity is highly sensitive to norm of the two vectors.",
      "D": "Cosine similarity can reflect the data similarity."
    },
    "Level-1 Topic": "Mathematics (for computer science and AI)",
    "Level-2 Topic": "Cosine similarity",
    "Rationale": "Cosine similarity measures the angle between vectors and reflects data similarity. It ranges from -1 to 1 and is not norm-sensitive.",
    "Answer": "AD"
  },
  {
    "Question": "(multi-answer) Which of the following statements regarding the law of large numbers are true? Select all that apply.",
    "Choices": {
      "A": "The law of large numbers states that as the sample size increases, the sample mean approaches the population mean.",
      "B": "The law of large numbers applies only to discrete random variables.",
      "C": "The law of large numbers guarantees that individual outcomes will always be close to the mean.",
      "D": "The law of large numbers is a theoretical concept but can benefit practical applications."
    },
    "Level-1 Topic": "Mathematics (for computer science and AI)",
    "Level-2 Topic": "Law of large numbers",
    "Rationale": "The law of large numbers states that sample means approach the population mean with larger samples. It’s theoretical but useful in practice.",
    "Answer": "AD"
  },
  {
    "Question": "(multi-answer) Which of the following statements are true regarding the properties of expected values and variance of discrete random variables? Select all that apply.",
    "Choices": {
      "A": "The expected value of a constant is equal to the constant itself.",
      "B": "The expected value of a sum of random variables is equal to the sum of their expected values.",
      "C": "The variance of a constant is equal to zero.",
      "D": "The variance of a sum of random variables is equal to the sum of their variances."
    },
    "Level-1 Topic": "Mathematics (for computer science and AI)",
    "Level-2 Topic": "Expected values and variance",
    "Rationale": "The expected value of a constant is the constant, the expectation of a sum is the sum, and a constant’s variance is zero. Variance of sums involves covariances.",
    "Answer": "ABC"
  },
  {
    "Question": "(multi-answer) Which of the following statements about gradients are true? Select all that apply.",
    "Choices": {
      "A": "Gradients are a vector quantity.",
      "B": "Gradients 0 indicate that the corresponding point is a global optimal solution.",
      "C": "Gradients can be used to optimize loss functions in machine learning.",
      "D": "Gradients are closely related to derivatives."
    },
    "Level-1 Topic": "Mathematics (for computer science and AI)",
    "Level-2 Topic": "Gradients",
    "Rationale": "Gradients are vectors, used to optimize loss functions, and relate to derivatives. Zero gradients don't guarantee global optimality.",
    "Answer": "ACD"
  },
  {
    "Question": "Which of the following statements about matrix multiplication are true? Select all that apply.",
    "Choices": {
      "A": "Matrix multiplication is not commutative in general, but it becomes commutative when one of the factors is an identity matrix, such that AB = BA.",
      "B": "The product of two matrices with dimensions m x n and p x q is a matrix with dimensions (m+n) x (p+q).",
      "C": "The product of two matrices is only defined if the number of columns in the first matrix is equal to the number of rows in the second matrix.",
      "D": "The number of rows in the first matrix must be equal to the number of columns in the second matrix for the operation to be valid."
    },
    "Level-1 Topic": "Mathematics (for computer science and AI)",
    "Level-2 Topic": "Matrix multiplication",
    "Rationale": "Matrix multiplication is generally non-commutative, even with an identity matrix. Defined if columns match rows.",
    "Answer": "AC"
  },
  {
    "Question": "Which of the following are properties of a good cryptographic hash function?",
    "Choices": {
      "A": "Collision resistance",
      "B": "Fast computation",
      "C": "One-way function",
      "D": "Fixed output length"
    },
    "Level-1 Topic": "Cybersecurity",
    "Level-2 Topic": "Cryptography",
    "Rationale": "A good cryptographic hash function must be collision-resistant, one-way, and produce a fixed output length to ensure security and data integrity, while speed is less critical.",
    "Answer": "ACD"
  },
  {
    "Question": "Which algorithms are examples of symmetric encryption?",
    "Choices": {
      "A": "AES",
      "B": "RSA",
      "C": "3DES",
      "D": "Blowfish"
    },
    "Level-1 Topic": "Cybersecurity",
    "Level-2 Topic": "Cryptography",
    "Rationale": "AES, 3DES, and Blowfish are all symmetric encryption algorithms that use the same key for both encryption and decryption, ensuring efficient data protection.",
    "Answer": "ACD"
  },
  {
    "Question": "What are common uses of public key encryption?",
    "Choices": {
      "A": "Secure email",
      "B": "Digital signatures",
      "C": "Data integrity",
      "D": "File compression"
    },
    "Level-1 Topic": "Cybersecurity",
    "Level-2 Topic": "Cryptography",
    "Rationale": "Public key encryption is utilized for secure email communications, creating digital signatures for authenticity, and ensuring data integrity, while file compression is unrelated to encryption.",
    "Answer": "ABC"
  },
  {
    "Question": "Which of the following are common types of firewalls?",
    "Choices": {
      "A": "Packet-filtering",
      "B": "Stateful inspection",
      "C": "Application-layer",
      "D": "Proxy"
    },
    "Level-1 Topic": "Cybersecurity",
    "Level-2 Topic": "Network security",
    "Rationale": "All listed types of firewalls—packet-filtering, stateful inspection, application-layer, and proxy—are used to control traffic and enhance network security through different methodologies.",
    "Answer": "ABCD"
  },
  {
    "Question": "Which protocols are used for secure communications?",
    "Choices": {
      "A": "HTTPS",
      "B": "SSL/TLS",
      "C": "FTP",
      "D": "SSH"
    },
    "Level-1 Topic": "Cybersecurity",
    "Level-2 Topic": "Network security",
    "Rationale": "HTTPS, SSL/TLS, and SSH provide secure communication channels over networks, encrypting data to protect against eavesdropping, while FTP lacks built-in security features.",
    "Answer": "ABD"
  },
  {
    "Question": "Which of the following can be used to detect network intrusions?",
    "Choices": {
      "A": "Firewalls",
      "B": "Intrusion Detection Systems (IDS)",
      "C": "Antivirus software",
      "D": "VPNs"
    },
    "Level-1 Topic": "Cybersecurity",
    "Level-2 Topic": "Network security",
    "Rationale": "IDS and antivirus software actively monitor and analyze network traffic for suspicious activities, while firewalls mainly block unauthorized access and VPNs secure connections.",
    "Answer": "BC"
  },
  {
    "Question": "Which of the following are common web application vulnerabilities?",
    "Choices": {
      "A": "SQL Injection",
      "B": "Cross-Site Scripting (XSS)",
      "C": "Buffer Overflow",
      "D": "Command Injection"
    },
    "Level-1 Topic": "Cybersecurity",
    "Level-2 Topic": "Web application security",
    "Rationale": "SQL Injection, XSS, and Command Injection are prevalent vulnerabilities in web applications that exploit user input, while buffer overflow primarily affects system memory rather than web applications.",
    "Answer": "ABD"
  },
  {
    "Question": "Which security measures can help protect against XSS attacks?",
    "Choices": {
      "A": "Input validation",
      "B": "Content Security Policy (CSP)",
      "C": "HTTPS",
      "D": "Secure cookies"
    },
    "Level-1 Topic": "Cybersecurity",
    "Level-2 Topic": "Web application security",
    "Rationale": "Input validation and CSP effectively mitigate XSS attacks by ensuring user inputs are sanitized and controlling which scripts can execute, while HTTPS and secure cookies enhance overall security.",
    "Answer": "AB"
  },
  {
    "Question": "Which methods are effective for preventing SQL Injection?",
    "Choices": {
      "A": "Parameterized queries",
      "B": "Input sanitization",
      "C": "Disabling HTTP methods",
      "D": "Web Application Firewalls (WAF)"
    },
    "Level-1 Topic": "Cybersecurity",
    "Level-2 Topic": "Web application security",
    "Rationale": "Parameterized queries, input sanitization, and WAFs are effective strategies to prevent SQL Injection by ensuring safe data handling and filtering malicious requests.",
    "Answer": "ABD"
  },
  {
    "Question": "Which types of malware can be classified as viruses?",
    "Choices": {
      "A": "File infector",
      "B": "Macro virus",
      "C": "Worms",
      "D": "Polymorphic virus"
    },
    "Level-1 Topic": "Cybersecurity",
    "Level-2 Topic": "Malware analysis",
    "Rationale": "File infectors, macro viruses, and polymorphic viruses all attach to legitimate files, spreading when the host file is executed, while worms are standalone malware.",
    "Answer": "ABD"
  },
  {
    "Question": "Which tools are commonly used for malware analysis?",
    "Choices": {
      "A": "IDA Pro",
      "B": "Wireshark",
      "C": "Cuckoo Sandbox",
      "D": "Metasploit"
    },
    "Level-1 Topic": "Cybersecurity",
    "Level-2 Topic": "Malware analysis",
    "Rationale": "IDA Pro and Cuckoo Sandbox are widely used for static and dynamic malware analysis, respectively, providing insights into malware behavior and characteristics.",
    "Answer": "AC"
  },
  {
    "Question": "Which techniques are used to analyze malware behavior?",
    "Choices": {
      "A": "Static analysis",
      "B": "Dynamic analysis",
      "C": "Behavioral analysis",
      "D": "Network analysis"
    },
    "Level-1 Topic": "Cybersecurity",
    "Level-2 Topic": "Malware analysis",
    "Rationale": "Static, dynamic, and behavioral analyses are essential techniques for understanding malware functionality, identifying patterns, and assessing its impact on systems.",
    "Answer": "ABC"
  },
  {
    "Question": "Which phases are part of a penetration testing process?",
    "Choices": {
      "A": "Reconnaissance",
      "B": "Scanning",
      "C": "Exploitation",
      "D": "Reporting"
    },
    "Level-1 Topic": "Cybersecurity",
    "Level-2 Topic": "Ethical hacking and penetration testing",
    "Rationale": "All listed phases—reconnaissance, scanning, exploitation, and reporting—are integral to penetration testing, guiding ethical hackers in identifying and mitigating vulnerabilities.",
    "Answer": "ABCD"
  },
  {
    "Question": "Which tools are commonly used in penetration testing?",
    "Choices": {
      "A": "Metasploit",
      "B": "Nmap",
      "C": "Wireshark",
      "D": "Nessus"
    },
    "Level-1 Topic": "Cybersecurity",
    "Level-2 Topic": "Ethical hacking and penetration testing",
    "Rationale": "Metasploit, Nmap, and Nessus are widely used tools for penetration testing, aiding in vulnerability assessment, network scanning, and exploitation of security weaknesses.",
    "Answer": "ABD"
  },
  {
    "Question": "Which legal considerations are important in ethical hacking?",
    "Choices": {
      "A": "Obtaining permission",
      "B": "Following regulations",
      "C": "Respecting privacy",
      "D": "Disabling security measures"
    },
    "Level-1 Topic": "Cybersecurity",
    "Level-2 Topic": "Ethical hacking and penetration testing",
    "Rationale": "Ethical hackers must obtain permission, comply with regulations, and respect privacy to ensure their activities are legal and ethical, avoiding legal repercussions.",
    "Answer": "ABC"
  },
  {
    "Question": "Aspects of visual perception are",
    "Choices": {
      "A": "Perceiving size and depth",
      "B": "Perceiving brightness",
      "C": "Perceiving color",
      "D": "Perceiving angle"
    },
    "Level-1 Topic": "Human-computer interaction",
    "Level-2 Topic": "Perception",
    "Rationale": "How we perceive size and depth, brightness and color, each of which is crucial to the design of effective visual interfaces.",
    "Answer": "ABC"
  },
  {
    "Question": "Color is usually regarded as being made up of components:",
    "Choices": {
      "A": "Hue",
      "B": "Intensity",
      "C": "Saturation",
      "D": "luminance"
    },
    "Level-1 Topic": "Human-computer interaction",
    "Level-2 Topic": "Perception",
    "Rationale": "Color is usually regarded as being made up of three components: hue, intensity and saturation.",
    "Answer": "ABC"
  },
  {
    "Question": "What types of problems can ergonomics solve?",
    "Choices": {
      "A": "Arrangement of controls and displays",
      "B": "The physical environment",
      "C": "Health issues",
      "D": "The use of color"
    },
    "Level-1 Topic": "Human-computer interaction",
    "Level-2 Topic": "ergonomics",
    "Rationale": "We consider a few of the issues addressed by ergonomics as an introduction to the field. We will briefly look at the arrangement of controls and displays, the physical environment, health issues and the use of color.",
    "Answer": "ABCD"
  },
  {
    "Question": "Which of the following factors should be considered in ergonomics to ensure user health and safety when designing a computer interface? (Select all that apply)",
    "Choices": {
      "A": "Physical position",
      "B": "Temperature",
      "C": "Lighting",
      "D": "Internet speed"
    },
    "Level-1 Topic": "Human-computer interaction",
    "Level-2 Topic": "ergonomics",
    "Rationale": "These are factors in the physical environment that directly affect the quality of the interaction and the user’s performance: Physical position, Temperature, Lighting Noise, Time.",
    "Answer": "ABC"
  },
  {
    "Question": "Which of the following accurately describe aspects of dialogue in user interface design? (Select all that apply)",
    "Choices": {
      "A": "The shape of icons and keys pressed (Lexical level)",
      "B": "The grammar and structure of inputs and outputs (Syntactic level)",
      "C": "The meaning and effects on internal data or the external world (Semantic level)",
      "D": "The resolution of conflict without interaction"
    },
    "Level-1 Topic": "Human-computer interaction",
    "Level-2 Topic": "Dialogue",
    "Rationale": "In user interface design, dialogue involves the lexical (icons and keys), syntactic (order and structure), and semantic (meaning and effects) levels. Conflict resolution without interaction does not describe dialogue accurately.",
    "Answer": "ABC"
  },
  {
    "Question": "Which of the following accurately describe challenges in interactive program design? (Select all that apply)",
    "Choices": {
      "A": "Calculations are interspersed with input-output, complicating the dialog.",
      "B": "The use of structured programming constructs always simplifies the program structure.",
      "C": "Error checking and correction are significant concerns in interactive programs.",
      "D": "If-then statements only represent system choices, not user choices."
    },
    "Level-1 Topic": "Human-computer interaction",
    "Level-2 Topic": "Dialogue",
    "Rationale": "Interactive programs often have mixed dialog and calculation structures, leading to complexity. Error checking is crucial, while structured programming does not always resolve these issues, and if-then statements handle both system and user choices.",
    "Answer": "AC"
  },
  {
    "Question": "Which of the following expert-based approaches can be used in the evaluation of design specifications?",
    "Choices": {
      "A": "GOMS model",
      "B": "Keystroke-level model",
      "C": "Design rationale",
      "D": "State transition networks"
    },
    "Level-1 Topic": "Human-computer interaction",
    "Level-2 Topic": "Evaluation",
    "Rationale": "All options listed are expert-based approaches used for evaluating design. GOMS and keystroke-level models predict performance, design rationale evaluates design options, and state transition networks assess dialog sequences.",
    "Answer": "ABCD"
  },
  {
    "Question": "Which of the following methods are used for evaluating systems through user participation?",
    "Choices": {
      "A": "Empirical methods",
      "B": "Observational methods",
      "C": "Eye tracking",
      "D": "Heuristic evaluation"
    },
    "Level-1 Topic": "Human-computer interaction",
    "Level-2 Topic": "Evaluation",
    "Rationale": "Empirical methods, observational methods, and eye tracking are user participation techniques for evaluating systems, whereas heuristic evaluation is an expert-based approach and not a user participation method.",
    "Answer": "ABC"
  },
  {
    "Question": "Which of the following categories are used to classify cognitive models according to their focus on either task acquisition or plan execution? (Select all that apply.)",
    "Choices": {
      "A": "Hierarchical representation of the user’s task and goal structure",
      "B": "Linguistic and grammatical models",
      "C": "Physical and device-level models",
      "D": "User interface design principles"
    },
    "Level-1 Topic": "Human-computer interaction",
    "Level-2 Topic": "Cognitive models",
    "Rationale": "Cognitive models are classified into hierarchical task structures, linguistic models, and physical/device-level models, based on their focus on either task acquisition or plan execution, not user interface design principles.",
    "Answer": "ABC"
  },
  {
    "Question": "Which of the following statements are true regarding Cognitive Complexity Theory (CCT) as discussed?",
    "Choices": {
      "A": "CCT can represent complex and concurrent plans.",
      "B": "CCT is commonly used to represent complex concurrent activities.",
      "C": "CCT is not typically used to represent concurrent activities.",
      "D": "CCT focuses on low-level, proceduralized goals rather than high-level planning."
    },
    "Level-1 Topic": "Human-computer interaction",
    "Level-2 Topic": "Cognitive models",
    "Rationale": "CCT can model complex plans and concurrent activities, but it is generally used for low-level tasks. It is not commonly used to represent simultaneous activities due to its focus on proceduralized goals.",
    "Answer": "ACD"
  },
  {
    "Question": "Consider the DAG X 1 ← X 2 → X 3.AssumethatalltheCPDsarelinear-Gaussian.Whichofthe \n following mat rices could be the covariance matrix?",
    "Choices": {
      "A": "A=\\left(\\begin{array}{lll}\n 9 & 3 & 1 \\\\\n 3 & 9 & 3 \\\\\n 1 & 3 & 9\n \\end{array}\\right)",
      "B": "B=\\left(\\begin{array}{ccc}\n 8 & -3 & 1 \\\\\n -3 & 9 & -3 \\\\\n 1 & -3 & 8\n \\end{array}\\right)",
      "C": "C=\\left(\\begin{array}{lll}\n 9 & 3 & 0 \\\\\n 3 & 9 & 3 \\\\\n 0 & 3 & 9\n \\end{array}\\right)",
      "D": "D=\\left(\\begin{array}{ccc}\n 9 & -3 & 0 \\\\\n -3 & 10 & -3 \\\\\n 0 & -3 & 9\n \\end{array}\\right)"
    },
    "Level-1 Topic": "Data science and big data",
    "Level-2 Topic": "Linear Gaussian models and covariance matrices",
    "Rationale": "Choices 1 and 4 are valid covariance matrices; they are symmetric and positive semi-definite, matching the required properties.",
    "Answer": "AD"
  },
  {
    "Question": "Which of the following factors have contributed to the huge success of data science in recent years? Select all that apply.",
    "Choices": {
      "A": "The availability of the rule-based approaches.",
      "B": "More powerful RAM, CPU, GPU, etc.",
      "C": "Huge volume of data.",
      "D": "Better models to fit the data."
    },
    "Level-1 Topic": "Data science and big data",
    "Level-2 Topic": "Factors contributing to data science success",
    "Rationale": "Data science thrives due to powerful hardware, vast data volumes, and advanced models.",
    "Answer": "BCD"
  },
  {
    "Question": "Which of the following statements are true about Naive Bayes classifiers? Select all that apply.",
    "Choices": {
      "A": "They are based on Bayes’ Formula, which allows us to invert conditional probabilities.",
      "B": "They are models that assign class labels to problem instances, represented as vectors of feature values.",
      "C": "Naive Bayes classifiers assume that the value of a particular feature is independent of the value of any other feature, given the class variable.",
      "D": "They are very effective when the features strongly correlate with each other."
    },
    "Level-1 Topic": "Machine learning",
    "Level-2 Topic": "Naive Bayes classifiers",
    "Rationale": "Naive Bayes uses Bayes' Formula, assigns labels to feature vectors, and assumes feature independence.",
    "Answer": "ABC"
  },
  {
    "Question": "Indicate all correct answers for each question.",
    "Choices": {
      "A": "Clustering partitions a given dataset into groups based on the given labels, so that the data points within a group are more similar to each other than the points in different groups.",
      "B": "K-means is a typical classification algorithm that can separate different classes in the feature space.",
      "C": "Linear classification can be viewed as the task of finding the linear separator that can separate different classes in the feature space.",
      "D": "Support vector machines with polynomial kernel and radial-basis function kernel can work on nonlinear classification problems."
    },
    "Level-1 Topic": "Machine learning",
    "Level-2 Topic": "Classification and clustering algorithms",
    "Rationale": "Linear classification finds a linear separator. SVMs with polynomial or RBF kernels handle nonlinear problems.",
    "Answer": "CD"
  },
  {
    "Question": "Which of the following statements about the application of data analytics are true? Select all that apply.",
    "Choices": {
      "A": "Data analytics can be used to identify patterns and trends in large datasets.",
      "B": "Data analytics can be used to optimize business processes and improve efficiency.",
      "C": "Data analytics can be used to make predictions and inform decision-making.",
      "D": "Data analytics can be used in various industries, including healthcare, finance, and marketing."
    },
    "Level-1 Topic": "Data science and big data",
    "Level-2 Topic": "Large-scale data analytics systems",
    "Rationale": "Data analytics is versatile and valuable for identifying patterns, optimizing processes, making predictions, and is applicable across various industries such as healthcare, finance, and marketing.",
    "Answer": "ABCD"
  },
  {
    "Question": "Which of the following statements are true regarding K-means clustering? Select all that apply.",
    "Choices": {
      "A": "K-means is an unsupervised learning algorithm.",
      "B": "The number of clusters in k-means is determined by the value of K.",
      "C": "K-means always converges to the global minimum of the objective function.",
      "D": "The initial placement of centroids in k-means has no impact on the final clustering result."
    },
    "Level-1 Topic": "Machine learning",
    "Level-2 Topic": "Unsupervised learning",
    "Rationale": "K-means is an unsupervised learning algorithm, and the number of clusters is determined by K. However, it does not always converge to the global minimum, and the initial centroid placement can impact the final results.",
    "Answer": "AB"
  },
  {
    "Question": "What are some properties of the sigmoid function? Select all that apply.",
    "Choices": {
      "A": "The sigmoid function is defined as f(x) = 1 / (1 + e^(-x)) .",
      "B": "The sigmoid function can be applied in logistic regression.",
      "C": "The sigmoid function has a range between 0 and 1.",
      "D": "The sigmoid function is not linear."
    },
    "Level-1 Topic": "Machine learning",
    "Level-2 Topic": "Artificial neural network",
    "Rationale": "The sigmoid function is defined as f(x) = 1 / (1 + e^(-x))​, is used in logistic regression, has a range between 0 and 1, and is nonlinear. These properties make it useful in various machine learning applications.",
    "Answer": "ABCD"
  },
  {
    "Question": "What methods are commonly used for parameter estimation in generalized linear models?",
    "Choices": {
      "A": "Ordinary Least Squares",
      "B": "Maximum Likelihood Estimation",
      "C": "Ridge Regression",
      "D": "Principal Component Analysis"
    },
    "Level-1 Topic": "Machine learning",
    "Level-2 Topic": "Supervised learning",
    "Rationale": "Because Ordinary Least Squares applies to linear models, and Maximum Likelihood Estimation is used for fitting a range of distributions within the generalized framework.",
    "Answer": "AB"
  },
  {
    "Question": "Which of the following are types of linear regression models?",
    "Choices": {
      "A": "Log-linear Regression",
      "B": "Logistic Regression",
      "C": "Multiple Linear Regression",
      "D": "Support Vector Regression"
    },
    "Level-1 Topic": "Machine learning",
    "Level-2 Topic": "Supervised learning",
    "Rationale": "Logistic regression is for classification and support vector regression is not a linear model.",
    "Answer": "AC"
  },
  {
    "Question": "What are the discriminative models?",
    "Choices": {
      "A": "Decision Trees",
      "B": "Bayesian Models",
      "C": "BP Neural Networks",
      "D": "Support Vector Machines"
    },
    "Level-1 Topic": "Machine learning",
    "Level-2 Topic": "Supervised learning",
    "Rationale": "Bayesian models are generative as they model the joint probability distribution of features and labels.",
    "Answer": "ACD"
  },
  {
    "Question": "Which attribute dependencies are considered by the semi-naive Bayes classifier?",
    "Choices": {
      "A": "Average One-Dependent Estimator",
      "B": "One-Dependent Estimator (ODE)",
      "C": "Super-Parent ODE",
      "D": "Tree Augmented Naive Bayes (TAN)"
    },
    "Level-1 Topic": "Machine learning",
    "Level-2 Topic": "Supervised learning",
    "Rationale": "Semi-naive Bayesian classifiers, like AODE and TAN, by allowing attribute dependencies while simplifying model complexity.",
    "Answer": "ABCD"
  },
  {
    "Question": "Which are included in unsupervised learning tasks?",
    "Choices": {
      "A": "Anomaly Detection",
      "B": "Density Estimation",
      "C": "Clustering",
      "D": "Dimensionality Reduction"
    },
    "Level-1 Topic": "Machine learning",
    "Level-2 Topic": "Unsupervised learning",
    "Rationale": "Unsupervised learning explores data structure without labeled responses, aiming to find patterns, or dimensional reductions.",
    "Answer": "ABCD"
  },
  {
    "Question": "Which are common external metrics for evaluating clustering performance?",
    "Choices": {
      "A": "Jaccard coefficient",
      "B": "Fowlkes-Mallows index",
      "C": "Davies-Bouldin index",
      "D": "Rand index"
    },
    "Level-1 Topic": "Machine learning",
    "Level-2 Topic": "Unsupervised learning",
    "Rationale": "Davies-Bouldin index belongs to internal metrics.  ",
    "Answer": "ABD"
  },
  {
    "Question": "The generation of a decision tree is a recursive process. The condition for recursion to terminate is:",
    "Choices": {
      "A": "All samples in the current node belong to the same class.",
      "B": "The current set of attributes is empty.",
      "C": "All samples have the same values for all attributes",
      "D": "The sample set in the current node is empty"
    },
    "Level-1 Topic": "Machine learning",
    "Level-2 Topic": "Supervised learning",
    "Rationale": "All situations have no attributes to be split or no samples for the next step. ",
    "Answer": "ABCD"
  },
  {
    "Question": "Which are strategies for Decision Tree to optimize spliting process?",
    "Choices": {
      "A": "pre-pruning",
      "B": "missing values processing",
      "C": "post-pruning",
      "D": "OC1"
    },
    "Level-1 Topic": "Machine learning",
    "Level-2 Topic": "Supervised learning",
    "Rationale": "OC1 is one method of multivariate decision tree. ",
    "Answer": "ABC"
  },
  {
    "Question": "Which are steps in the data preprocessing?",
    "Choices": {
      "A": "Data cleaning",
      "B": "Data integration",
      "C": "Data reduction",
      "D": "Data transformation"
    },
    "Level-1 Topic": "Data science and big data",
    "Level-2 Topic": "Data mining",
    "Rationale": "Data preprocessing techniques can improve data quality. ",
    "Answer": "ABCD"
  },
  {
    "Question": "Which are data smoothing techniques?",
    "Choices": {
      "A": "Binning",
      "B": "Regression",
      "C": "Outlier analysis",
      "D": "Field overloading"
    },
    "Level-1 Topic": "Data science and big data",
    "Level-2 Topic": "Data mining",
    "Rationale": "These three methods aim to find noise and change values by binning neighborhood or regression etc. ",
    "Answer": "ABC"
  },
  {
    "Question": "Which are included in dmensionality reduction methods?",
    "Choices": {
      "A": "wavelet transforms",
      "B": "principal components analysis",
      "C": "clustering",
      "D": "sampling"
    },
    "Level-1 Topic": "Data science and big data",
    "Level-2 Topic": "Data mining",
    "Rationale": "These methods transform or project the original data onto a smaller space. ",
    "Answer": "AB"
  },
  {
    "Question": "Which discriptions are correct in the basic procedures of PCA?",
    "Choices": {
      "A": "The input data are normalized, so that each attribute falls within the same range. This\nstep helps ensure that attributes with large domains will not dominate attributes with\nsmaller domains.",
      "B": "PCA computes k orthonormal vectors that provide a basis for the normalized input\ndata.",
      "C": "The principal components are sorted in order of decreasing “significance” or\nstrength.",
      "D": "Because the components are sorted in decreasing order of “significance,” the data size\ncan be reduced by eliminating the weaker components"
    },
    "Level-1 Topic": "Data science and big data",
    "Level-2 Topic": "Data mining",
    "Rationale": "PCA “combines” the essence of attributes by creating an alternative, smaller set of variables. The initial data can then be projected onto this smaller\nset. PCA often reveals relationships that were not previously suspected and thereby\nallows interpretations that would not ordinarily result.",
    "Answer": "ABCD"
  },
  {
    "Question": "Outlier detection is useful in many applications yet faces many challenges. Which are possible challenges?",
    "Choices": {
      "A": "Modeling normal objects and outliers effectively",
      "B": "Application-specific outlier detection",
      "C": "Handling noise in outlier detection",
      "D": "Understandability"
    },
    "Level-1 Topic": "Data science and big data",
    "Level-2 Topic": "Data mining",
    "Rationale": "Challenges in outlier detection include effectively modeling normal objects versus outliers, tailoring methods to specific applications, handling noise which can affect detection accuracy, and ensuring that detection methods are understandable and interpretable.",
    "Answer": "ABCD"
  },
  {
    "Question": "Which does outlier detection methods for high-dimensional data meet the challenges?",
    "Choices": {
      "A": "Interpretation of outliers",
      "B": "Data sparsity",
      "C": "Data subspaces",
      "D": "Scalability with respect to dimensionality"
    },
    "Level-1 Topic": "Data science and big data",
    "Level-2 Topic": "Data mining",
    "Rationale": "Outlier detection methods for high-dimensional data address challenges by focusing on data subspaces to manage sparsity, scalability to handle large dimensions, and ensuring interpretation of outliers despite the complexity of high-dimensional spaces.",
    "Answer": "ABCD"
  },
  {
    "Question": "Which of the following are common approaches used in recommender systems?",
    "Choices": {
      "A": "Collaborative filtering",
      "B": "Content-based filtering",
      "C": "Keyword matching",
      "D": "Demographic-based filtering"
    },
    "Level-1 Topic": "Information retrieval",
    "Level-2 Topic": "Recommender system",
    "Rationale": "Recommender systems often use collaborative filtering, content-based filtering, and demographic-based filtering to provide personalized recommendations.",
    "Answer": "ABD"
  },
  {
    "Question": "What are some challenges faced by recommender systems?",
    "Choices": {
      "A": "Cold start problem",
      "B": "Data sparsity",
      "C": "High computational cost",
      "D": "User interface design"
    },
    "Level-1 Topic": "Information retrieval",
    "Level-2 Topic": "Recommender system",
    "Rationale": "Recommender systems face challenges like cold start, data sparsity, and high computational costs, impacting their effectiveness.",
    "Answer": "ABC"
  },
  {
    "Question": "Which metrics are commonly used to evaluate recommender systems?",
    "Choices": {
      "A": "Precision",
      "B": "Recall",
      "C": "F1 Score",
      "D": "Click-through rate"
    },
    "Level-1 Topic": "Information retrieval",
    "Level-2 Topic": "Recommender system",
    "Rationale": "Precision, recall, F1 score, and click-through rate are essential metrics for evaluating recommender systems, providing insights into accuracy, relevance, and user interaction with recommendations.",
    "Answer": "ABCD"
  },
  {
    "Question": "Which techniques are often employed to improve recommendation accuracy?",
    "Choices": {
      "A": "Ensemble methods",
      "B": "Matrix factorization",
      "C": "User segmentation",
      "D": "A/B testing"
    },
    "Level-1 Topic": "Information retrieval",
    "Level-2 Topic": "Recommender system",
    "Rationale": "Ensemble methods, matrix factorization, and user segmentation enhance recommendation accuracy by combining multiple approaches, analyzing user behavior, and leveraging diverse data sources for improved predictions.",
    "Answer": "ABCD"
  },
  {
    "Question": "Which components are essential for a web search engine?",
    "Choices": {
      "A": "Crawler",
      "B": "Indexer",
      "C": "Query processor",
      "D": "User interface"
    },
    "Level-1 Topic": "Information retrieval",
    "Level-2 Topic": "Web search",
    "Rationale": "A crawler gathers data, an indexer organizes it, and a query processor retrieves relevant information, making these components essential for efficient web search engine functionality.",
    "Answer": "ABC"
  },
  {
    "Question": "What techniques are commonly used to improve search relevance?",
    "Choices": {
      "A": "Personalization",
      "B": "Semantic search",
      "C": "Keyword stuffing",
      "D": "Query expansion"
    },
    "Level-1 Topic": "Information retrieval",
    "Level-2 Topic": "Web search",
    "Rationale": "Personalization, semantic search, and query expansion improve search relevance by tailoring results to individual user needs, understanding context, and broadening search queries for better matches.",
    "Answer": "ABD"
  },
  {
    "Question": "Which models are commonly used in information retrieval?",
    "Choices": {
      "A": "Boolean model",
      "B": "Vector space model",
      "C": "Probabilistic model",
      "D": "Neural network model"
    },
    "Level-1 Topic": "Information retrieval",
    "Level-2 Topic": "Information retrieval models",
    "Rationale": "Boolean, vector space, and probabilistic models are foundational to information retrieval, each offering unique methodologies for ranking and retrieving documents based on user queries.",
    "Answer": "ABC"
  },
  {
    "Question": "Which characteristics are associated with the vector space model?",
    "Choices": {
      "A": "Uses term frequency",
      "B": "Represents documents as vectors",
      "C": "Requires exact matches",
      "D": "Measures similarity using cosine similarity"
    },
    "Level-1 Topic": "Information retrieval",
    "Level-2 Topic": "Information retrieval models",
    "Rationale": "The vector space model utilizes term frequency, represents documents as vectors, and measures similarity through cosine similarity, allowing for effective ranking and retrieval based on document relevance.",
    "Answer": "ABD"
  },
  {
    "Question": "Which of the following are advantages of the probabilistic model?",
    "Choices": {
      "A": "Handles uncertainty",
      "B": "Provides ranked results",
      "C": "Requires extensive manual tuning",
      "D": "Considers user behavior"
    },
    "Level-1 Topic": "Information retrieval",
    "Level-2 Topic": "Information retrieval models",
    "Rationale": "The probabilistic model effectively handles uncertainty, provides ranked results, and incorporates user behavior, making it a powerful tool for predicting document relevance based on statistical analysis.",
    "Answer": "ABD"
  },
  {
    "Question": "Which challenges are associated with information retrieval models?",
    "Choices": {
      "A": "Scalability",
      "B": "Query ambiguity",
      "C": "High storage requirements",
      "D": "User satisfaction measurement"
    },
    "Level-1 Topic": "Information retrieval",
    "Level-2 Topic": "Information retrieval models",
    "Rationale": "Scalability, query ambiguity, and user satisfaction measurement present significant challenges in information retrieval models, complicating their implementation and effectiveness in real-world applications.",
    "Answer": "ABD"
  },
  {
    "Question": "Which of the following statements about the vector space model are true?",
    "Choices": {
      "A": "It allows for partial matching of queries.",
      "B": "It requires exact term matches.",
      "C": "It can incorporate term weights.",
      "D": "It ranks documents based on geometric distance."
    },
    "Level-1 Topic": "Information retrieval",
    "Level-2 Topic": "Information retrieval models",
    "Rationale": "The vector space model supports partial matching, incorporates term weights for relevance, and ranks documents by evaluating the geometric distance between query and document vectors.",
    "Answer": "ACD"
  },
  {
    "Question": "Which of the following are features of the probabilistic model in information retrieval?",
    "Choices": {
      "A": "It uses binary relevance.",
      "B": "It estimates relevance probabilities.",
      "C": "It strictly follows Boolean logic.",
      "D": "It can adapt to user feedback."
    },
    "Level-1 Topic": "Information retrieval",
    "Level-2 Topic": "Information retrieval models",
    "Rationale": "The probabilistic model focuses on estimating the likelihood of relevance and can adapt based on user interactions, enhancing its predictive capability.",
    "Answer": "BD"
  },
  {
    "Question": "What does tf-idf help to achieve in information retrieval?",
    "Choices": {
      "A": "Rank documents",
      "B": "Reduce storage needs",
      "C": "Identify important terms",
      "D": "Enhance query processing"
    },
    "Level-1 Topic": "Information retrieval",
    "Level-2 Topic": "Tf–idf",
    "Rationale": "Tf-idf effectively ranks documents by highlighting significant terms, allowing for improved search relevance and better identification of important keywords within a document collection.",
    "Answer": "AC"
  },
  {
    "Question": "Which factors influence the calculation of tf-idf?",
    "Choices": {
      "A": "Term frequency",
      "B": "Document frequency",
      "C": "User behavior",
      "D": "Document length"
    },
    "Level-1 Topic": "Information retrieval",
    "Level-2 Topic": "Tf–idf",
    "Rationale": "Term frequency, document frequency, and document length are crucial factors in calculating tf-idf, influencing the importance of terms in the context of information retrieval.",
    "Answer": "ABD"
  },
  {
    "Question": "What are the limitations of using tf-idf?",
    "Choices": {
      "A": "Ignores word semantics",
      "B": "Sensitive to document length",
      "C": "Requires extensive training data",
      "D": "Cannot handle synonyms"
    },
    "Level-1 Topic": "Information retrieval",
    "Level-2 Topic": "Tf–idf",
    "Rationale": "Tf-idf's limitations include ignoring word semantics, being sensitive to document length, and struggling with synonyms, which restrict its effectiveness in fully capturing textual meaning.",
    "Answer": "ABD"
  },
  {
    "Question": "What are the main benefits of using an inverted index?",
    "Choices": {
      "A": "Fast retrieval",
      "B": "Reduced redundancy",
      "C": "Simplified data structure",
      "D": "Efficient storage"
    },
    "Level-1 Topic": "Information retrieval",
    "Level-2 Topic": "Inverted index",
    "Rationale": "An inverted index provides fast retrieval, reduces redundancy, and enables efficient storage, optimizing the search process by organizing term-document relationships for quicker access.",
    "Answer": "ABD"
  },
  {
    "Question": "Which components are typically included in an inverted index?",
    "Choices": {
      "A": "List of terms",
      "B": "Document identifiers",
      "C": "Term frequency counts",
      "D": "User profiles"
    },
    "Level-1 Topic": "Information retrieval",
    "Level-2 Topic": "Inverted index",
    "Rationale": "An inverted index includes a list of terms, document identifiers, and term frequency counts, facilitating efficient lookups and enhancing the speed of information retrieval.",
    "Answer": "ABC"
  },
  {
    "Question": "In which scenarios would an inverted index be less effective?",
    "Choices": {
      "A": "Small datasets",
      "B": "Frequent updates",
      "C": "Real-time search",
      "D": "Querying relational databases"
    },
    "Level-1 Topic": "Information retrieval",
    "Level-2 Topic": "Inverted index",
    "Rationale": "An inverted index is less effective for small datasets and structured queries in databases, where simpler indexing methods may suffice and retrieval speed is not as critical.",
    "Answer": "AD"
  },
  {
    "Question": "Which of the following is a common technique for word embeddings?",
    "Choices": {
      "A": "Bert Embeddings",
      "B": "Bag of Words",
      "C": "Word2Vec",
      "D": "Term Frequency-Inverse Document Frequency (TF-IDF)"
    },
    "Level-1 Topic": "NLP",
    "Level-2 Topic": "Morphology analysis",
    "Rationale": "All of them can represent words in a continuous vector space, capturing semantic relationships between words based on their context in large text corpora.",
    "Answer": "ABCD"
  },
  {
    "Question": "Which of the following techniques are commonly used in Morphological Analysis for Natural Language Processing?",
    "Choices": {
      "A": "Stemming",
      "B": "Lemmatization",
      "C": "N-gram Modeling",
      "D": "Affixation"
    },
    "Level-1 Topic": "NLP",
    "Level-2 Topic": "Morphology analysis",
    "Rationale": "N-gram Modeling (D) is related to syntactic and statistical analysis rather than directly to morphological analysis.",
    "Answer": "ABD"
  },
  {
    "Question": "In the context of Semantic Analysis in NLP, which of the following statements are true?",
    "Choices": {
      "A": "Semantic analysis focuses on the meaning of words and sentences.",
      "B": "It is only applicable to English and other major languages.",
      "C": "Semantic ambiguity can arise from polysemy and homonymy.",
      "D": "Semantic analysis can enhance information retrieval systems."
    },
    "Level-1 Topic": "NLP",
    "Level-2 Topic": "Semantic analysis",
    "Rationale": "semantic analysis techniques can be applied to a wide range of languages, not just major ones.",
    "Answer": "ACD"
  },
  {
    "Question": "Which of the following are challenges faced in Semantic Analysis?",
    "Choices": {
      "A": "Ambiguity in word meanings",
      "B": "Contextual variations in meaning",
      "C": "Lack of sufficient training data",
      "D": "Syntactic errors in text"
    },
    "Level-1 Topic": "NLP",
    "Level-2 Topic": "Semantic analysis",
    "Rationale": "Syntactic errors in text, while problematic for overall text processing, are more related to syntactic analysis rather than semantic analysis specifically.",
    "Answer": "ABC"
  },
  {
    "Question": "Which of the following techniques are commonly used in Syntactic Analysis for Natural Language Processing?",
    "Choices": {
      "A": "Dependency Parsing",
      "B": "Constituency Parsing",
      "C": "Named Entity Recognition",
      "D": "Tokenization"
    },
    "Level-1 Topic": "NLP",
    "Level-2 Topic": "Syntactic Analysis",
    "Rationale": "Named Entity Recognition is related to semantic analysis, focusing on identifying and classifying entities in text rather than analyzing syntactic structure.",
    "Answer": "ABD"
  },
  {
    "Question": "Which of the following statements accurately describe the differences between Dependency Parsing and Constituency Parsing in Syntactic Analysis?",
    "Choices": {
      "A": "Dependency Parsing focuses on the relationships between individual words, while Constituency Parsing focuses on the hierarchical structure of phrases.",
      "B": "Constituency Parsing can only handle context-free grammars, whereas Dependency Parsing can handle both context-free and context-sensitive grammars.",
      "C": "Dependency Parsing produces a tree structure where nodes represent words, while Constituency Parsing produces a tree structure where nodes represent phrases.",
      "D": "Dependency Parsing is generally more computationally intensive than Constituency Parsing due to its complexity in handling relationships."
    },
    "Level-1 Topic": "NLP",
    "Level-2 Topic": "Syntactic Analysis",
    "Rationale": "In practice, dependency parsing can often be more efficient and less computationally intensive than constituency parsing, depending on the implementation and the specific algorithms used.",
    "Answer": "AC"
  },
  {
    "Question": "In the context of NLP applications, which of the following statements are true?",
    "Choices": {
      "A": "Chatbots utilize NLP to understand and respond to user queries.",
      "B": "Text summarization is a technique used to condense large volumes of text into shorter summaries.",
      "C": "NLP can only be applied to written text and not to spoken language.",
      "D": "Information Retrieval systems leverage NLP to improve search results based on user queries."
    },
    "Level-1 Topic": "NLP",
    "Level-2 Topic": "Applications of Natural Language Processing (NLP)",
    "Rationale": "NLP encompasses both written and spoken language processing, including tasks like speech recognition and natural language understanding.",
    "Answer": "ABD"
  },
  {
    "Question": "Which of the following statements accurately describe advanced applications of Natural Language Processing?",
    "Choices": {
      "A": "Named Entity Recognition (NER) can be used to extract specific information such as names, dates, and locations from unstructured text.",
      "B": "Topic Modeling is primarily used for sentiment analysis by categorizing text based on emotional tone.",
      "C": "Text-to-Speech (TTS) systems convert written text into spoken words, utilizing NLP for natural language understanding.",
      "D": "Automatic Speech Recognition (ASR) systems rely on NLP techniques to transcribe spoken language into text format."
    },
    "Level-1 Topic": "NLP",
    "Level-2 Topic": "Applications of Natural Language Processing (NLP)",
    "Rationale": "topic modeling is a technique used to discover abstract topics within a collection of documents, not specifically for sentiment analysis. It focuses on identifying themes rather than emotional content.",
    "Answer": "ACD"
  },
  {
    "Question": "Which of the following are commonly used activation functions in artificial neural networks?",
    "Choices": {
      "A": "Sigmoid",
      "B": "ReLU",
      "C": "Softmax",
      "D": "Linear Regression"
    },
    "Level-1 Topic": "Computer Vision",
    "Level-2 Topic": "Artificial Neural Network",
    "Rationale": "Sigmoid, ReLU, and Softmax are all activation functions commonly used in neural networks. Sigmoid is often used in binary classification, ReLU is widely used in hidden layers due to its efficiency, and Softmax is used in multi-class classification to produce probabilities.",
    "Answer": "ABC"
  },
  {
    "Question": "In the context of training artificial neural networks, which of the following statements are true?",
    "Choices": {
      "A": "Overfitting occurs when the model learns the training data too well, including noise.",
      "B": "Training data and validation data should be the same to ensure the model is accurate.",
      "C": "Regularization techniques help to prevent overfitting.",
      "D": "The learning rate determines how much the weights are updated during training."
    },
    "Level-1 Topic": "Computer Vision",
    "Level-2 Topic": "Artificial Neural Network",
    "Rationale": "Overfitting indeed occurs when a model becomes too complex and learns noise, and regularization techniques are applied to mitigate this issue. The learning rate is also critical as it affects the speed of convergence during training. However, training and validation data should be separate; sharing them would not validate the model's performance correctly.",
    "Answer": "ACD"
  },
  {
    "Question": "Which of the following methods are used for 3D reconstruction? (Select all that apply)",
    "Choices": {
      "A": "Stereo Vision",
      "B": "Structure from Motion (SfM)",
      "C": "Depth Mapping",
      "D": "Image Filtering"
    },
    "Level-1 Topic": "Computer Vision",
    "Level-2 Topic": "3D Reconstruction",
    "Rationale": "Stereo Vision, SfM, and Depth Mapping are all methods employed in 3D reconstruction to derive spatial information and create 3D models. Image Filtering, however, is related to enhancing images rather than directly reconstructing 3D structures.",
    "Answer": "ABC"
  },
  {
    "Question": "In 3D reconstruction, which of the following statements is correct? (Select all that apply)",
    "Choices": {
      "A": "3D reconstruction can be done from a single image.",
      "B": "3D models can only be created using laser scanning technologies.",
      "C": "Multi-view geometry involves using multiple images taken from different angles.",
      "D": "Depth cameras provide direct measurements of the distance to surfaces."
    },
    "Level-1 Topic": "Computer Vision",
    "Level-2 Topic": "3D Reconstruction",
    "Rationale": "It is possible to reconstruct 3D information from a single image using techniques like single-image depth estimation. Multi-view geometry indeed involves analyzing multiple images for better accuracy. Depth cameras provide direct measurements, making 3D reconstruction more precise, while laser scanning is one method but not the only means to create 3D models.",
    "Answer": "ACD"
  },
  {
    "Question": "Which image processing techniques are commonly used for enhancing an image? (Select all that apply)",
    "Choices": {
      "A": "Histogram Equalization",
      "B": "Noise Reduction",
      "C": "Image Segmentation",
      "D": "Color Quantization"
    },
    "Level-1 Topic": "Computer Vision",
    "Level-2 Topic": "Image Processing Operations",
    "Rationale": "Histogram Equalization and Noise Reduction are techniques aimed at enhancing image quality. Histogram Equalization improves contrast, while Noise Reduction helps in removing unwanted noise from images. Image Segmentation categorizes parts of an image, and Color Quantization reduces the number of colors but does not enhance quality directly.",
    "Answer": "AB"
  },
  {
    "Question": "In image processing, which of the following operations can be used for feature extraction?",
    "Choices": {
      "A": "Convolution",
      "B": "Image Resizing",
      "C": "Edge Detection",
      "D": "Filtering"
    },
    "Level-1 Topic": "Computer Vision",
    "Level-2 Topic": "Image Processing Operations",
    "Rationale": "Convolution, Edge Detection, and Filtering are crucial for feature extraction as they help in identifying specific patterns or structures in an image. Image Resizing alters the dimensions of the image but does not directly contribute to feature extraction.",
    "Answer": "ACD"
  },
  {
    "Question": "Which of the following algorithms are known for object detection tasks?",
    "Choices": {
      "A": "YOLO (You Only Look Once)",
      "B": "Faster R-CNN",
      "C": "k-Nearest Neighbors (k-NN)",
      "D": "Single Shot MultiBox Detector (SSD)"
    },
    "Level-1 Topic": "Computer Vision",
    "Level-2 Topic": "Object Detection",
    "Rationale": "YOLO, Faster R-CNN, and SSD are all popular object detection algorithms that perform efficiently in identifying and localizing objects within images. k-NN is a classification algorithm and not specifically designed for object detection.",
    "Answer": "ABD"
  },
  {
    "Question": "In the context of object detection, what do the terms \"contained\" and \"partially visible\" refer to?",
    "Choices": {
      "A": "The detection of objects fully within the frame of the image.",
      "B": "The detection of objects that are only partially in view.",
      "C": "The ability of a model to identify multiple objects regardless of visibility.",
      "D": "The accuracy of detection is not affected by the object's position."
    },
    "Level-1 Topic": "Computer Vision",
    "Level-2 Topic": "Object Detection",
    "Rationale": "\"Contained\" refers to objects that are fully visible within the frame, while \"partially visible\" relates to objects that are only partially in view. A well-designed object detection model should be able to identify both types effectively, but its accuracy can be affected by the object's position.",
    "Answer": "ABC"
  },
  {
    "Question": "Which of the following are applications of computer vision?",
    "Choices": {
      "A": "Autonomous Vehicles",
      "B": "Social Media Image Filters",
      "C": "Data Entry Automation",
      "D": "Medical Diagnosis from Imaging"
    },
    "Level-1 Topic": "Computer Vision",
    "Level-2 Topic": "Applications of Computer Vision",
    "Rationale": "Autonomous vehicles use computer vision for navigation and obstacle detection, social media filters typically leverage computer vision for effects, and medical diagnosis from imaging (like MRIs and X-rays) relies on computer vision techniques for analysis. Data Entry Automation is more related to NLP (Natural Language Processing) rather than computer vision.",
    "Answer": "ACD"
  },
  {
    "Question": "Which of the following statements about computer vision applications are true?",
    "Choices": {
      "A": "Computer vision can improve accessibility for visually impaired individuals.",
      "B": "Computer vision applications are limited to image processing only.",
      "C": "Computer vision can help automate quality inspections in manufacturing.",
      "D": "Facial recognition systems can utilize computer vision techniques."
    },
    "Level-1 Topic": "Computer Vision",
    "Level-2 Topic": "Applications of Computer Vision",
    "Rationale": "Computer vision can indeed aid in developing solutions for accessibility, automate inspections in various industries, and implement facial recognition systems for security and verification. However, stating that computer vision applications are limited to image processing is incorrect, as they encompass various domains, including real-time analysis and automation.",
    "Answer": "ACD"
  },
  {
    "Question": "Which of the following statements about FOL-FC-ASK are true?",
    "Choices": {
      "A": "It is sound because every inference uses Generalized Modus Ponens.",
      "B": "t is complete for knowledge bases with definite clauses.",
      "C": "It can only handle propositional logic queries.",
      "D": "It does not answer every query entailed by definite clause knowledge bases."
    },
    "Level-1 Topic": "Artificial intelligence introduction",
    "Level-2 Topic": "Forward chaining",
    "Rationale": "FOL-FC-ASK is sound due to Generalized Modus Ponens and complete for definite clause knowledge bases, ensuring all entailments are answered. It is not limited to propositional logic.",
    "Answer": "AB"
  },
  {
    "Question": "Which of the following inefficiencies are associated with the forward-chaining algorithm as described?",
    "Choices": {
      "A": "The inner loop matches every rule against every fact in the knowledge base.",
      "B": "The algorithm checks only the most recent rules in each iteration.",
      "C": "The algorithm rechecks every rule on every iteration.",
      "D": "The algorithm generates irrelevant facts not related to the goal."
    },
    "Level-1 Topic": "Artificial intelligence introduction",
    "Level-2 Topic": "Forward chaining",
    "Rationale": "The inefficiencies of the forward-chaining algorithm include matching all rules to all facts, rechecking all rules each iteration, and generating irrelevant facts. The algorithm does not limit checks to recent rules",
    "Answer": "ACD"
  },
  {
    "Question": "Which of the following statements are true about Prolog's execution and design? (Select all that apply.)",
    "Choices": {
      "A": "Prolog executes programs using depth-first backward chaining, trying clauses in the order they appear in the knowledge base.",
      "B": "Prolog treats equality and negation using first-order semantics.",
      "C": "Prolog includes built-in functions for arithmetic that execute code rather than performing logical inference.",
      "D": "Prolog’s depth-first backward chaining search may lead to non-termination if the program has infinite recursion."
    },
    "Level-1 Topic": "Artificial intelligence introduction",
    "Level-2 Topic": "Backward chaining",
    "Rationale": "Prolog uses depth-first backward chaining, executes arithmetic through built-in functions, and may fail to terminate due to infinite recursion, while omitting the occur check and using database semantics.",
    "Answer": "ACD"
  },
  {
    "Question": "Which statements accurately describe features of tabled logic programming? (Select all that apply.)",
    "Choices": {
      "A": "Tabled logic programming combines backward chaining with forward chaining efficiency through dynamic programming.",
      "B": "It is incomplete for Datalog knowledge bases and may require careful management to avoid infinite loops.",
      "C": "Tabled logic programming stores intermediate results to avoid duplication of efforts.",
      "D": "It is guaranteed to handle predicates with potentially unbounded numbers of objects without risking infinite loops."
    },
    "Level-1 Topic": "Artificial intelligence introduction",
    "Level-2 Topic": "Backward chaining",
    "Rationale": "Tabled logic programming uses dynamic programming for efficiency and stores intermediate results to prevent duplication, while it is complete for Datalog but can still face infinite loops with certain predicates.",
    "Answer": "AC"
  },
  {
    "Question": "Which of the following statements are true regarding knowledge bases containing only definite clauses?",
    "Choices": {
      "A": "Every definite clause can be written as an implication with a conjunction of positive literals in the premise and a single positive literal in the conclusion.",
      "B": "Horn form implies that the premise is called the head and the conclusion is called the body.",
      "C": "Forward-chaining and backward-chaining algorithms are used for inference with Horn clauses.",
      "D": "Deciding entailment with Horn clauses can be performed in time linear to the size of the knowledge base."
    },
    "Level-1 Topic": "Artificial intelligence introduction",
    "Level-2 Topic": "Knowledge base",
    "Rationale": "Definite clauses can be represented as implications, and inference with them uses efficient algorithms like forward-chaining and backward-chaining. Entailment in Horn clauses is also computationally efficient.",
    "Answer": "ACD"
  },
  {
    "Question": "Which of the following statements are true about how a logical agent operates using its knowledge base?",
    "Choices": {
      "A": "The knowledge base consists only of percept sentences obtained from the agent's experience.",
      "B": "A logical agent deduces actions from a knowledge base of axioms and percept sentences.",
      "C": "The knowledge base is used to deduce the current state of the wumpus world.",
      "D": "Axioms in the knowledge base represent specific experiences of the agent in the world."
    },
    "Level-1 Topic": "Artificial intelligence introduction",
    "Level-2 Topic": "Knowledge base",
    "Rationale": "A logical agent uses both axioms (general knowledge) and percept sentences (specific experiences) to deduce actions and the current state of its environment.",
    "Answer": "BC"
  },
  {
    "Question": "Which of the following are desirable properties of knowledge representation languages?",
    "Choices": {
      "A": "Declarative",
      "B": "Context-dependent",
      "C": "Compositional",
      "D": "Expressive"
    },
    "Level-1 Topic": "Artificial intelligence introduction",
    "Level-2 Topic": "Knowledge representation language",
    "Rationale": "Knowledge representation languages should be declarative (specifying what is true), compositional (allowing complex expressions from simpler ones), and expressive (capturing a wide range of ideas), but not context-dependent or ambiguous.",
    "Answer": "ACD"
  },
  {
    "Question": "Which of the following statements are true regarding the impact of knowledge representation languages?",
    "Choices": {
      "A": "Different representations can impact the efficiency of deriving conclusions, even if the facts are the same.",
      "B": "For nondeductive tasks like learning from experience, the representation language does not influence outcomes.",
      "C": "Choosing between theories that fit the data often depends on the succinctness of the representation language used.",
      "D": "Formal logic asserts that all representations are equivalent in terms of derivability, regardless of their structure."
    },
    "Level-1 Topic": "Artificial intelligence introduction",
    "Level-2 Topic": "Knowledge representation language",
    "Rationale": "Different representations can affect how efficiently conclusions are derived. In learning tasks, the choice of representation language affects which theory is selected based on succinctness.",
    "Answer": "AC"
  },
  {
    "Question": "Which of the following are true about the semantic network notation and its inheritance reasoning capabilities?",
    "Choices": {
      "A": "Semantic networks allow inheritance reasoning by following MemberOf and SubsetOf links.",
      "B": "Inheritance reasoning in semantic networks is less efficient than semidecidable logical theorem proving.",
      "C": "The semantic network notation helps determine properties like the number of legs Mary has.",
      "D": "Semantic networks are not suitable for representing hierarchical relationships."
    },
    "Level-1 Topic": "Artificial intelligence introduction",
    "Level-2 Topic": "Knowledge representation and reasoning",
    "Rationale": "Semantic networks efficiently perform inheritance reasoning through hierarchical links, making property determination simple and effective, unlike semidecidable logical theorem proving, which is less efficient in this context.",
    "Answer": "AC"
  },
  {
    "Question": "Which of the following statements are true about nonmonotonic reasoning and logic?",
    "Choices": {
      "A": "Nonmonotonic reasoning allows conclusions to be retracted when new evidence contradicts previous assumptions.",
      "B": "Probability theory guarantees that the set of beliefs grows monotonically over time.",
      "C": "Nonmonotonic logics, such as circumscription and default logic, aim to handle reasoning where beliefs can be revised.",
      "D": "Nonmonotonic reasoning assumes that conclusions are fixed and cannot be changed with new evidence."
    },
    "Level-1 Topic": "Artificial intelligence introduction",
    "Level-2 Topic": "Knowledge representation and reasoning",
    "Rationale": "Nonmonotonic reasoning is characterized by the ability to retract conclusions based on new evidence. Nonmonotonic logics, like circumscription and default logic, address this behavior, while probability theory typically assumes a more monotonic growth of beliefs.",
    "Answer": "AB"
  },
  {
    "Question": "Which of the following planning methods are extended to handle partially observable, nondeterministic, and unknown environments?",
    "Choices": {
      "A": "Sensorless planning",
      "B": "Contingency planning",
      "C": "Online planning and replanning",
      "D": "Classical planning"
    },
    "Level-1 Topic": "Artificial intelligence introduction",
    "Level-2 Topic": "Automated planning and scheduling",
    "Rationale": "Sensorless, contingency, and online planning are designed for complex environments, while classical planning does not handle partial observability or nondeterminism, making it unsuitable for these cases.",
    "Answer": "ABC"
  },
  {
    "Question": "Which of the following approaches are used by an online agent for monitoring the environment during plan execution? (Select all that apply)",
    "Choices": {
      "A": "Action monitoring",
      "B": "Plan monitoring",
      "C": "Goal monitoring",
      "D": "Risk assessment"
    },
    "Level-1 Topic": "Artificial intelligence introduction",
    "Level-2 Topic": "Automated planning and scheduling",
    "Rationale": "Action, plan, and goal monitoring are key strategies used by online agents to adapt their plans based on current conditions and effectiveness. Risk assessment is not mentioned.",
    "Answer": "ABC"
  }
]